{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit706cd4c46de74bd79acda9c50bcb14f5",
   "display_name": "Python 3.7.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "6455be0ba6d313e61fa561a59feb5f13d5e5fc4d538f6449aef2b51328fb9b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycaret\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_variables = ['T2','T24','T30','T50','P2','P15','P30','Nf','Nc','epr','Ps30','phi','NRf','NRc','BPR','farB','htBleed','Nf_dmd','PCNfR_dmd','W31','W32']\n",
    "\n",
    "column_names = ['id','cycle']\n",
    "features = ['o'+str(n) for n in range(1,4)]\n",
    "features.extend(output_variables)\n",
    "column_names.extend(features)\n",
    "train_files = [f'train_FD00{i}.txt' for i in range(1,5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfs = []\n",
    "for train_file in train_files:    \n",
    "    train_dfs.append(pd.read_csv(f'data/{train_file}',header=None,sep='\\s+',names=column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split between train and validation ##\n",
    "split = 0.7\n",
    "train_df = train_dfs[2]\n",
    "units = set(train_df['id'].unique())\n",
    "train_units = random.sample(units,k=int(split*len(units)))\n",
    "val_units = units-set(train_units)\n",
    "train_set = train_df[train_df['id'].isin(train_units)].copy().reset_index(drop=True)\n",
    "val_set = train_df[train_df['id'].isin(val_units)].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RUL Calculation ##\n",
    "max_cycles = train_set.groupby('id').max()['cycle']\n",
    "rul = train_set.set_index('id')[['cycle']].apply(lambda x: max_cycles[x.name]-x,axis=1)\n",
    "train_set['RUL'] = rul.values\n",
    "train_set.drop(columns=['id','cycle'],inplace=True)"
   ]
  },
  {
   "source": [
    "# Data Pre-Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "x_train = train_set.loc[:,train_set.var() > 10**-10].drop(columns=['RUL'])  #drop columns with zero variance\n",
    "y_train = train_set['RUL']\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "x_train = pd.DataFrame(scaler.transform(x_train),columns=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving mean and variance\n",
    "scaler_mean = scaler.mean_\n",
    "scaler_var = scaler.var_"
   ]
  },
  {
   "source": [
    "# Sklearn Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}